# ğŸ§  Classifieur de textes avec RNN (PyTorch)

## ğŸ“Œ Contexte acadÃ©mique
Projet rÃ©alisÃ© dans le cadre du **Master 2 Intelligence Artificielle**  
UniversitÃ© Claude Bernard Lyon 1 â€“ DÃ©partement Informatique  
UE : **Intelligence Bio-InspirÃ©e**

## ğŸ¯ Objectif
DÃ©velopper un **classifieur de textes** basÃ© sur un **RÃ©seau de Neurones RÃ©current (RNN)** en utilisant **PyTorch**.  
Lâ€™objectif principal Ã©tait de traiter un dataset de phrases Ã©tiquetÃ©es par sentiments et de concevoir un modÃ¨le capable de **prÃ©dire correctement lâ€™Ã©motion associÃ©e Ã  un texte**.

## âœ¨ FonctionnalitÃ©s implÃ©mentÃ©es
- ğŸ”¹ **Chargement et prÃ©traitement des donnÃ©es**
  - DÃ©coupage du dataset en `train`, `validation`, et `test`
  - Fonction `load_file(file)` pour parser les textes et labels
  - Nettoyage des mots rares (filtrage TF-IDF)
- ğŸ”¹ **Encodage des donnÃ©es**
  - CrÃ©ation dâ€™un dictionnaire `mot â†’ id`
  - Gestion du **padding** pour uniformiser les phrases
  - Encodage **one-hot** et **embedding learnable**
- ğŸ”¹ **ModÃ¨le RNN (PyTorch)**
  - ImplÃ©mentation dâ€™une classe `RNN(nn.Module)`
  - Ajout dâ€™une couche dâ€™embedding pour amÃ©liorer la reprÃ©sentation des mots
  - Support du traitement par batch avec `DataLoader`
- ğŸ”¹ **Boucle dâ€™apprentissage**
  - EntraÃ®nement par `epoch/batch` avec suivi des courbes
  - Validation croisÃ©e pour prÃ©venir lâ€™overfitting
  - Utilisation de fonctions de perte adaptÃ©es pour gÃ©rer le dÃ©sÃ©quilibre des classes
- ğŸ”¹ **Ã‰valuations et visualisations**
  - Courbes **accuracy & loss** (train/validation)
  - **Matrice de confusion** sur le jeu de test
  - Visualisation des embeddings (PCA, t-SNE)
- ğŸ”¹ **Approfondissements**
  - ReprÃ©sentation distribuÃ©e des mots
  - ExpÃ©rimentation avec apprentissage auto-supervisÃ© (prÃ©diction `contexte â†’ mot`)

## ğŸ› ï¸ Stack technique
- **Langage :** Python 3  
- **BibliothÃ¨ques principales :** PyTorch, Torchtext, Scikit-learn, Matplotlib, NumPy  
- **Outils :** Jupyter Notebook, Git  
